{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from datetime import time\n",
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# os.chdir('C:/Users/zzlen/OneDrive - Seattle University/MSBA/5. Fall 2022/BUAN 5510/Capstone Project/Yelp Review/JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_business = pd.read_csv('final_business_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y dataset\n",
    "\n",
    "cols_to_drop = ['business_id', 'business_name', 'city', 'state', 'postal_code', 'categories', 'stars']\n",
    "\n",
    "X = final_business.drop(cols_to_drop, axis=1)\n",
    "y = final_business['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5012, 47), (1253, 47), (5012,), (1253,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split training and testing dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1234)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "params = {\n",
    "        'learning_rate': list(np.arange(0.1, 0.6, 0.1)),\n",
    "        'n_estimators' : list(np.arange(100, 600, 100)),\n",
    "        'max_depth'    : [3, 5, 10, 15],\n",
    "        'subsample'    : [1.0, 2.0, 3.0]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "480 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 2.0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 3.0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83599572        nan        nan 0.83573074        nan        nan\n",
      " 0.8342089         nan        nan 0.83101249        nan        nan\n",
      " 0.83475204        nan        nan 0.83129473        nan        nan\n",
      " 0.82840436        nan        nan 0.82489357        nan        nan\n",
      " 0.81414364        nan        nan 0.81254767        nan        nan\n",
      " 0.8122045         nan        nan 0.8112492         nan        nan\n",
      " 0.75092234        nan        nan 0.74972875        nan        nan\n",
      " 0.75106137        nan        nan 0.75074434        nan        nan\n",
      " 0.83449194        nan        nan 0.83203574        nan        nan\n",
      " 0.82852902        nan        nan 0.82362671        nan        nan\n",
      " 0.82562123        nan        nan 0.82022184        nan        nan\n",
      " 0.81610069        nan        nan 0.81212094        nan        nan\n",
      " 0.80650207        nan        nan 0.80331836        nan        nan\n",
      " 0.80577155        nan        nan 0.80440767        nan        nan\n",
      " 0.74997655        nan        nan 0.75070086        nan        nan\n",
      " 0.75132735        nan        nan 0.74710735        nan        nan\n",
      " 0.83127746        nan        nan 0.82586005        nan        nan\n",
      " 0.82069639        nan        nan 0.81609453        nan        nan\n",
      " 0.81888966        nan        nan 0.80952568        nan        nan\n",
      " 0.80522641        nan        nan 0.80132776        nan        nan\n",
      " 0.79644252        nan        nan 0.79713666        nan        nan\n",
      " 0.796988          nan        nan 0.797929          nan        nan\n",
      " 0.74853993        nan        nan 0.75153351        nan        nan\n",
      " 0.75169438        nan        nan 0.75236874        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "src = GridSearchCV(estimator= gbr, param_grid= params)\n",
    "src.fit(X, y)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   **Report**\n",
      "The best estimator: GradientBoostingRegressor()\n",
      "The best parameters:\n",
      " {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "The best score: 0.8360\n",
      "Total run time for GridSearchCV: 6771.35 seconds\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n   **Report**')\n",
    "print(f'The best estimator: {src.best_estimator_}')\n",
    "print(f'The best parameters:\\n {src.best_params_}')\n",
    "print(f'The best score: {src.best_score_:.4f}')\n",
    "print(f'Total run time for GridSearchCV: {(end - start):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gs = pd.DataFrame(src.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.663119</td>\n",
       "      <td>0.383074</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}</td>\n",
       "      <td>0.831260</td>\n",
       "      <td>0.836312</td>\n",
       "      <td>0.829878</td>\n",
       "      <td>0.835901</td>\n",
       "      <td>0.846627</td>\n",
       "      <td>0.835996</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 2.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 3.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.630767</td>\n",
       "      <td>0.102595</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}</td>\n",
       "      <td>0.830077</td>\n",
       "      <td>0.836306</td>\n",
       "      <td>0.831902</td>\n",
       "      <td>0.834750</td>\n",
       "      <td>0.845619</td>\n",
       "      <td>0.835731</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 2.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.005420</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 300, 'subsample': 2.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>300</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 300, 'subsample': 3.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>9.956391</td>\n",
       "      <td>0.399448</td>\n",
       "      <td>0.030141</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 500, 'subsample': 1.0}</td>\n",
       "      <td>0.743086</td>\n",
       "      <td>0.749880</td>\n",
       "      <td>0.749189</td>\n",
       "      <td>0.745899</td>\n",
       "      <td>0.773790</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 500, 'subsample': 2.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 500, 'subsample': 3.0}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         1.663119      0.383074         0.006174        0.001147   \n",
       "1         0.004746      0.000751         0.000000        0.000000   \n",
       "2         0.005387      0.001017         0.000000        0.000000   \n",
       "3         2.630767      0.102595         0.007370        0.001192   \n",
       "4         0.004986      0.000892         0.000000        0.000000   \n",
       "..             ...           ...              ...             ...   \n",
       "139       0.005420      0.000843         0.000000        0.000000   \n",
       "140       0.005278      0.000943         0.000000        0.000000   \n",
       "141       9.956391      0.399448         0.030141        0.000415   \n",
       "142       0.005738      0.001048         0.000000        0.000000   \n",
       "143       0.005571      0.001200         0.000000        0.000000   \n",
       "\n",
       "    param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "0                   0.1               3                100             1.0   \n",
       "1                   0.1               3                100             2.0   \n",
       "2                   0.1               3                100             3.0   \n",
       "3                   0.1               3                200             1.0   \n",
       "4                   0.1               3                200             2.0   \n",
       "..                  ...             ...                ...             ...   \n",
       "139                 0.3              15                300             2.0   \n",
       "140                 0.3              15                300             3.0   \n",
       "141                 0.3              15                500             1.0   \n",
       "142                 0.3              15                500             2.0   \n",
       "143                 0.3              15                500             3.0   \n",
       "\n",
       "                                                                             params  \\\n",
       "0     {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}   \n",
       "1     {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 2.0}   \n",
       "2     {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 3.0}   \n",
       "3     {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}   \n",
       "4     {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 2.0}   \n",
       "..                                                                              ...   \n",
       "139  {'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 300, 'subsample': 2.0}   \n",
       "140  {'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 300, 'subsample': 3.0}   \n",
       "141  {'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 500, 'subsample': 1.0}   \n",
       "142  {'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 500, 'subsample': 2.0}   \n",
       "143  {'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 500, 'subsample': 3.0}   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0             0.831260           0.836312           0.829878   \n",
       "1                  NaN                NaN                NaN   \n",
       "2                  NaN                NaN                NaN   \n",
       "3             0.830077           0.836306           0.831902   \n",
       "4                  NaN                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "139                NaN                NaN                NaN   \n",
       "140                NaN                NaN                NaN   \n",
       "141           0.743086           0.749880           0.749189   \n",
       "142                NaN                NaN                NaN   \n",
       "143                NaN                NaN                NaN   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.835901           0.846627         0.835996        0.005882   \n",
       "1                  NaN                NaN              NaN             NaN   \n",
       "2                  NaN                NaN              NaN             NaN   \n",
       "3             0.834750           0.845619         0.835731        0.005398   \n",
       "4                  NaN                NaN              NaN             NaN   \n",
       "..                 ...                ...              ...             ...   \n",
       "139                NaN                NaN              NaN             NaN   \n",
       "140                NaN                NaN              NaN             NaN   \n",
       "141           0.745899           0.773790         0.752369        0.010984   \n",
       "142                NaN                NaN              NaN             NaN   \n",
       "143                NaN                NaN              NaN             NaN   \n",
       "\n",
       "     rank_test_score  \n",
       "0                  1  \n",
       "1                112  \n",
       "2                111  \n",
       "3                  2  \n",
       "4                110  \n",
       "..               ...  \n",
       "139               59  \n",
       "140               62  \n",
       "141               37  \n",
       "142              124  \n",
       "143              144  \n",
       "\n",
       "[144 rows x 17 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomizedSearchCV - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "params = {\n",
    "        'learning_rate': list(np.arange(0.1, 0.6, 0.1)),\n",
    "        'n_estimators' : list(np.arange(100, 600, 100)),\n",
    "        'max_depth'    : [3, 5, 10, 15],\n",
    "        'subsample'    : [1.0, 2.0, 3.0]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 317, in _check_params\n",
      "    raise ValueError(\"subsample must be in (0,1] but was %r\" % self.subsample)\n",
      "ValueError: subsample must be in (0,1] but was 3.0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\zzlen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.75372858        nan 0.80330736 0.75238544 0.82894142]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start_r = time.time()\n",
    "\n",
    "rand_src = RandomizedSearchCV(estimator= gbr, param_distributions = params, \n",
    "                                                                  n_iter=6)\n",
    "rand_src.fit(X,y)\n",
    "\n",
    "end_r = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   **Report**\n",
      "The best estimator: GradientBoostingRegressor(max_depth=5, n_estimators=300)\n",
      "The best parameters:\n",
      " {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "The best score: 0.8289\n",
      "Total run time for RandomizedSearchCV: 241.98 seconds\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n   **Report**')\n",
    "print(f'The best estimator: {rand_src.best_estimator_}')\n",
    "print(f'The best parameters:\\n {rand_src.best_params_}')\n",
    "print(f'The best score: {rand_src.best_score_:.4f}')\n",
    "print(f'Total run time for RandomizedSearchCV: {(end_r - start_r):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the details of search\n",
    "results_rgs = pd.DataFrame(rand_src.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014367</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'subsample': 3.0, 'n_estimators': 100, 'max_depth': 15, 'learning_rate': 0.1}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.140045</td>\n",
       "      <td>0.944665</td>\n",
       "      <td>0.037746</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 1.0, 'n_estimators': 200, 'max_depth': 15, 'learning_rate': 0.3}</td>\n",
       "      <td>0.747534</td>\n",
       "      <td>0.750058</td>\n",
       "      <td>0.744910</td>\n",
       "      <td>0.750843</td>\n",
       "      <td>0.775299</td>\n",
       "      <td>0.753729</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 3.0, 'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.3}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.025890</td>\n",
       "      <td>0.134755</td>\n",
       "      <td>0.026724</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'subsample': 1.0, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.3}</td>\n",
       "      <td>0.799613</td>\n",
       "      <td>0.808708</td>\n",
       "      <td>0.789291</td>\n",
       "      <td>0.801876</td>\n",
       "      <td>0.817049</td>\n",
       "      <td>0.803307</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.191958</td>\n",
       "      <td>1.131723</td>\n",
       "      <td>0.030534</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'subsample': 1.0, 'n_estimators': 100, 'max_depth': 15, 'learning_rate': 0.2}</td>\n",
       "      <td>0.749211</td>\n",
       "      <td>0.741599</td>\n",
       "      <td>0.747017</td>\n",
       "      <td>0.759251</td>\n",
       "      <td>0.764847</td>\n",
       "      <td>0.752385</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.554235</td>\n",
       "      <td>0.026705</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'subsample': 1.0, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "      <td>0.825817</td>\n",
       "      <td>0.831427</td>\n",
       "      <td>0.823116</td>\n",
       "      <td>0.825996</td>\n",
       "      <td>0.838351</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.014367      0.007538         0.000000        0.000000   \n",
       "1      13.140045      0.944665         0.037746        0.002392   \n",
       "2       0.006769      0.000756         0.000000        0.000000   \n",
       "3      15.025890      0.134755         0.026724        0.000759   \n",
       "4       9.191958      1.131723         0.030534        0.001031   \n",
       "5       8.554235      0.026705         0.018340        0.000503   \n",
       "\n",
       "  param_subsample param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0             3.0                100              15                 0.1   \n",
       "1             1.0                200              15                 0.3   \n",
       "2             3.0                300              10                 0.3   \n",
       "3             1.0                500               5                 0.3   \n",
       "4             1.0                100              15                 0.2   \n",
       "5             1.0                300               5                 0.1   \n",
       "\n",
       "                                                                           params  \\\n",
       "0  {'subsample': 3.0, 'n_estimators': 100, 'max_depth': 15, 'learning_rate': 0.1}   \n",
       "1  {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 15, 'learning_rate': 0.3}   \n",
       "2  {'subsample': 3.0, 'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.3}   \n",
       "3   {'subsample': 1.0, 'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.3}   \n",
       "4  {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 15, 'learning_rate': 0.2}   \n",
       "5   {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1           0.747534           0.750058           0.744910           0.750843   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3           0.799613           0.808708           0.789291           0.801876   \n",
       "4           0.749211           0.741599           0.747017           0.759251   \n",
       "5           0.825817           0.831427           0.823116           0.825996   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                NaN              NaN             NaN                5  \n",
       "1           0.775299         0.753729        0.010984                3  \n",
       "2                NaN              NaN             NaN                6  \n",
       "3           0.817049         0.803307        0.009275                2  \n",
       "4           0.764847         0.752385        0.008458                4  \n",
       "5           0.838351         0.828941        0.005424                1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time is 1.3903477191925049 seconds\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predGB = gbr.predict(X_test)\n",
    "\n",
    "t_end = time.time()\n",
    "execution_time = t_end - t_start\n",
    "print (f'Execution time is {execution_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **Evaluation of Errors**\n",
      " mse:  0.07304683902349611 \n",
      " rmse: 0.27027178732434526\n",
      " R^2:  0.8371287035412842\n"
     ]
    }
   ],
   "source": [
    "gbr_mse = metrics.mean_squared_error(y_test,y_predGB)\n",
    "gbr_rmse = np.sqrt(gbr_mse)\n",
    "gbr_rsquared = gbr.score(X_test, y_test)\n",
    "print('\\n', '**Evaluation of Errors**')\n",
    "print (' mse: ', gbr_mse,'\\n','rmse:', gbr_rmse)\n",
    "print (' R^2: ', gbr_rsquared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
